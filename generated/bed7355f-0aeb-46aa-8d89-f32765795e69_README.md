# üëã Welcome to bed7355f-0aeb-46aa-8d89-f32765795e69

üìÑ *This documentation was automatically generated by [CodeScribe AI](https://github.com/Mahi1609/codescribe_ai.git)*

---

## üß† Overview
### Code File Summaries

The project is a Python-based invoice extraction tool utilizing Optical Character Recognition (OCR) and a local Ollama Large Language Model (LLM). The primary functionality is encapsulated in the `main.py` file, which orchestrates the following key steps: 
* Extracting text from a PDF file using OCR
* Preprocessing the extracted text
* Sending the preprocessed text to the Ollama model for invoice field extraction
* Saving the structured output to a JSON file. 
The project relies on several custom modules, including `ocr_handler`, `ollama_parser`, and `text_cleaner`, to perform these tasks.

---

## üîç What Does This Project Do?
This project is designed to ### Code File Summaries

#### PROJECT_PURPOSE
This project is designed to extract invoice fields from PDF files using Optical Character Recognition (OCR) and a local Ollama Large Language Model (LLM).

#### main.py
**Purpose:** Extract invoice fields from a given PDF file.
**Key Functions:**
* `main(pdf_path)`: The primary entry point for the script, responsible for orchestrating the extraction process.
* `extract_text_from_pdf(pdf_path)`: Performs OCR extraction on the provided PDF file.
* `generate_invoice_fields(cleaned_text)`: Sends the preprocessed text to the local Ollama model to extract structured invoice fields.
* `clean_ocr_text(text)`: Preprocesses the extracted text to improve the accuracy of the LLM.
**Inputs:**
* `pdf_path`: The path to the PDF file to be processed.
**Outputs:**
* A JSON file containing the extracted invoice fields and the raw response from the Ollama model.
**Side-Effects:**
* Creates an "output" directory if it does not exist.
* Saves the extracted output to a JSON file in the "output" directory.
**Dependencies:**
* `os` for cross-platform path normalization and directory creation.
* `sys` for command-line argument parsing.
* `json` for output serialization.
* `ocr.ocr_handler` for OCR extraction.
* `llm.ollama_parser` for invoice field extraction using the Ollama LLM.
* `utils.text_cleaner` for text preprocessing.

#### Other Files
* `debug_ocr.py`: Not summarized, as its purpose is not evident from the provided context.
* `llm/ollama_parser.py`: Contains the `generate_invoice_fields` function, which interacts with the local Ollama model.
* `ocr/ocr_handler.py`: Contains the `extract_text_from_pdf` function, responsible for OCR extraction.
* `utils/text_cleaner.py`: Contains the `clean_ocr_text` function, used for text preprocessing.

---

## üõ† Tech Stack Used
- **Detected Environment:** `python`
- **Languages & Frameworks:**


  - Python

  - Node

  - System



---

## üì¶ Dependencies


### Python


- PIL

- fitz

- llm

- ocr

- pytesseract

- requests



### Node

- No dependencies detected


### System


- Install Ollama from https://ollama.ai (required for running local LLMs).

- Install Tesseract OCR (e.g., `sudo apt-get install tesseract-ocr`).







---

## ‚öôÔ∏è Installation & Run
To get started with this project:

### Clone the repository
```bash
git clone <your-repo-url>
cd bed7355f-0aeb-46aa-8d89-f32765795e69
```

### (Optional) Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
```

### Install dependencies

```bash
pip install -r requirements.txt
```


### How to run
```bash
## Clone the repository
git clone <your-repo-url>
cd bed7355f-0aeb-46aa-8d89-f32765795e69

## Install dependencies
pip install -r requirements.txt

## Run the app
python main.py
```

---

## üß© Code File Summaries

### üìÑ `debug_ocr.py`
### Code File Summaries: debug_ocr.py

**Purpose:** 
The `debug_ocr.py` script extracts and displays text from a PDF file using Optical Character Recognition (OCR) for debugging purposes.

**Key Components:**
* The primary function, `debug_ocr`, takes a PDF file path as input and prints extracted text for each page.
* The `extract_text_from_pdf` function from the `ocr.ocr_handler` module is utilized for text extraction.

**Functionality:**
* The script accepts a PDF file path as a command-line argument and prints the extracted text for each page, displaying only the first 1000 characters with an ellipsis (`...`) indicating additional text.
* If the required command-line argument is not provided, the script prints usage instructions.

**Dependencies and Requirements:**
* Custom `ocr.ocr_handler` module for OCR tasks
* Indirect reliance on `PIL`, `fitz`, `llm`, `ocr`, `pytesseract`, and `requests` libraries
* `tesseract-ocr` system package and `ollama` library (for local LLMs) are required for the project, although not directly used in this script

**Usage:**
To run the script, execute it from the command line, providing the path to a PDF file as an argument:
```bash
python debug_ocr.py /path/to/example.pdf
```


### üìÑ `main.py`
### main.py Summary

**Purpose:** 
The `main.py` script extracts invoice fields from a given PDF file using Optical Character Recognition (OCR) and a local Ollama Large Language Model (LLM).

**Key Components:**
* Orchestrates invoice extraction via `main(pdf_path)`
* Utilizes OCR for text extraction from PDFs
* Employs a local Ollama model for structured invoice field extraction
* Cleans extracted OCR text for preprocessing

**Functionality:**
* Takes a PDF file path as input
* Outputs:
  + Structured invoice fields to the console
  + A JSON file containing raw model output and structured invoice fields to the `output` directory
* Creates the `output` directory if it does not exist

**Dependencies:**
* Python libraries: `PIL`, `fitz`, `llm`, `ocr`, `pytesseract`, `requests`
* External dependencies: `Ollama` AI model, `Tesseract OCR`

**Usage:**
* Run via command line: `python main.py <path_to_pdf>`


### üìÑ `llm/ollama_parser.py`
### Code File Summaries: `llm/ollama_parser.py`

The `ollama_parser.py` file is designed to parse invoice text and extract structured information using a local Large Language Model (LLM) API. 

* **Purpose**: Extract relevant fields from invoice text via a local LLM API.
* **Key Functions**:
  * `generate_invoice_fields(text)`: Sends a prompt to the local LLM API and returns parsed data in JSON format.
* **Inputs/Outputs**:
  * Input: `text` (string) - invoice text to be parsed
  * Outputs: 
    + `json_data` (dict) - parsed invoice data in JSON format
    + `raw_output` (string) - raw output from the LLM API or an error message
* **Side-Effects**:
  * Sends a POST request to the local LLM API at `http://localhost:11434/api/generate`
  * Returns a default empty JSON object if the API request fails
* **Important Dependencies**:
  * `requests` library for HTTP requests
  * Local LLM API (e.g., Ollama) running on `http://localhost:11434`
* **Behavior and Intent**: The `generate_invoice_fields` function extracts relevant information from invoice text using a local LLM API, returning the extracted data in JSON format. If the API request fails, it returns a default empty JSON object.


### üìÑ `ocr/ocr_handler.py`
### ocr_handler.py Summary

**Purpose:** 
The `ocr_handler.py` file contains a function to extract text from scanned PDFs using Optical Character Recognition (OCR).

**Key Components:**
* `extract_text_from_pdf` function: extracts text from each page of a scanned PDF.

**Functionality:**
* Input: `pdf_path` (str) - the path to the scanned PDF file.
* Output: A dictionary (`extracted_pages`) where keys are page numbers (prefixed with "page_") and values are the extracted text from each page.
* Side-Effects:
  * Raises a `FileNotFoundError` if the specified PDF file does not exist.
  * Opens and closes the PDF document using `fitz`.
* Dependencies:
  * `fitz` (PyMuPDF) for PDF processing.
  * `pytesseract` for OCR functionality.
  * `PIL` (Python Imaging Library) for image processing.
  * Tesseract OCR (system dependency).

**Behavior and Intent:**
The `extract_text_from_pdf` function uses OCR to extract text from scanned PDFs by converting each page to a high-DPI image and applying `pytesseract` for text extraction, storing the results in a dictionary with page numbers as keys.


### üìÑ `utils/text_cleaner.py`
### Code File Summaries: `utils/text_cleaner.py`

The `text_cleaner.py` module is designed to clean and normalize text extracted from Optical Character Recognition (OCR) processes. 

* **Purpose**: Improve OCR text readability and usability for further processing.
* **Key Functions**:
  * `clean_ocr_text(text)`: Cleans the input OCR text.
* **Inputs and Outputs**:
  * **Input**: `text` (string) - Raw OCR text.
  * **Output**: `text` (string) - Cleaned and normalized OCR text.
* **Side-Effects**: None.
* **Important Dependencies**: Python's built-in `re` (regular expression) module.
* **Behavior and Intent**: 
  * Removes extra whitespaces and line breaks.
  * Fixes broken words with hyphenations at line ends.
  * Normalizes punctuation and special characters.
  * Replaces common misread characters and words.
  * Strips leading and trailing whitespaces.
 
This module serves as a preprocessing step for OCR text, making it suitable for tasks like text analysis, information extraction, or machine learning model input.

