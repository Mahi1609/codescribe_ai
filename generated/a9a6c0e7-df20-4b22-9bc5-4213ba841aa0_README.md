# üëã Welcome to a9a6c0e7-df20-4b22-9bc5-4213ba841aa0

üìÑ *This documentation was automatically generated by [CodeScribe AI](https://github.com/Mahi1609/codescribe_ai.git)*

---

## üß† Overview
### Code File Summaries

The project is designed to extract invoice fields from PDF files using Optical Character Recognition (OCR) and a local Ollama LLM (Large Language Model). The main entry point, `main.py`, orchestrates this process by: 
* Extracting text from PDFs via the `ocr_handler` module
* Preprocessing the extracted text with the `text_cleaner` utility
* Sending the cleaned text to the Ollama model for invoice field extraction using the `ollama_parser` module
* Saving the structured output to a JSON file. 
Key dependencies include the `ocr_handler`, `ollama_parser`, and `text_cleaner` modules, which are crucial for the project's functionality.

---

## üîç What Does This Project Do?
This project is designed to ### Code File Summaries

#### PROJECT_PURPOSE
This project is designed to extract invoice fields from PDF files using Optical Character Recognition (OCR) and a local Ollama Large Language Model (LLM).

#### main.py
**Purpose:** Extract invoice fields from a PDF file and save the structured output to a JSON file.
**Key Functions:**
* `main(pdf_path)`: The main entry point of the script, responsible for orchestrating the invoice extraction process.
* `extract_text_from_pdf(pdf_path)`: Extracts text from a PDF file using OCR (defined in `ocr/ocr_handler.py`).
* `generate_invoice_fields(cleaned_text)`: Sends the preprocessed text to the local Ollama model to extract invoice fields (defined in `llm/ollama_parser.py`).
* `clean_ocr_text(text)`: Preprocesses the extracted text before sending it to the Ollama model (defined in `utils/text_cleaner.py`).
**Inputs:**
* `pdf_path`: The path to the PDF file to extract invoice fields from.
**Outputs:**
* A JSON file containing the structured invoice fields and the raw output from the Ollama model.
**Side-Effects:**
* Creates an `output` directory if it does not exist.
* Saves the structured output to a JSON file in the `output` directory.
**Important Dependencies:**
* None detected, but the code relies on the `os`, `sys`, and `json` modules.
**Framework Patterns:**
* The code uses a modular approach, with separate modules for OCR handling, Ollama model interaction, and text cleaning. 

Some key points about the code:
* The script takes a PDF file path as a command-line argument.
* It normalizes the PDF file path for cross-platform compatibility.
* It extracts text from the PDF file using OCR and preprocesses the text before sending it to the Ollama model.
* It saves the structured output to a JSON file in the `output` directory. 

To run the script, save it as `main.py` and execute it from the command line, providing the path to a PDF file as an argument: `python main.py <path_to_pdf>`.

---

## üõ† Tech Stack Used
- **Detected Environment:** `python`
- **Languages & Frameworks:**


  - Python

  - Node

  - System



---

## üì¶ Dependencies


### Python


- PIL

- fitz

- llm

- ocr

- pytesseract

- requests



### Node

- No dependencies detected


### System


- Install Ollama from https://ollama.ai (required for running local LLMs).

- Install Tesseract OCR (e.g., `sudo apt-get install tesseract-ocr`).







---

## ‚öôÔ∏è Installation & Run
To get started with this project:

### Clone the repository
```bash
git clone <your-repo-url>
cd a9a6c0e7-df20-4b22-9bc5-4213ba841aa0
```

### (Optional) Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
```

### Install dependencies

```bash
pip install -r requirements.txt
```


### How to run
```bash
## Clone the repository
git clone <your-repo-url>
cd a9a6c0e7-df20-4b22-9bc5-4213ba841aa0

## Install dependencies
pip install -r requirements.txt

## Run the app
python main.py
```

---

## üß© Code File Summaries

### üìÑ `debug_ocr.py`
### debug_ocr.py

**Purpose:** 
The `debug_ocr.py` script is designed to extract and display text from a PDF file using Optical Character Recognition (OCR) for debugging purposes.

**Key Components:**
* The script utilizes the `extract_text_from_pdf` function from the `ocr.ocr_handler` module to extract text from PDF files.
* It takes a PDF file path as input, extracts text from each page, and prints the extracted text to the console.

**Behavior and Dependencies:**
* The script relies on external dependencies such as PIL, fitz, llm, ocr, pytesseract, and requests, as well as system dependencies like Ollama and Tesseract OCR.
* It uses the `sys` module to access command-line arguments and does not modify the input PDF file or create new files.

**Usage and Output:**
* To run the script, execute it from the command line with a PDF file path as an argument: `python debug_ocr.py <pdf_path>`.
* The script prints extracted text from each page to the console, truncating it to 1000 characters with an ellipsis if more text is available.


### üìÑ `main.py`
### main.py Summary

**Purpose:** 
The `main.py` script extracts invoice fields from a given PDF file using Optical Character Recognition (OCR) and a local Ollama Large Language Model (LLM).

**Key Components:**
* Orchestrates invoice extraction using OCR and LLM
* Utilizes `extract_text_from_pdf`, `generate_invoice_fields`, and `clean_ocr_text` functions

**Functionality:**
* Extracts text from PDF using OCR
* Preprocesses OCR text for LLM input
* Generates structured invoice fields using Ollama LLM
* Saves extracted fields and raw LLM response to JSON file

**Inputs/Outputs:**
* Input: PDF file path (command-line argument)
* Outputs:
  + JSON file with extracted invoice fields and raw LLM response
  + Console output displaying extraction process and results

**Dependencies:**
* Python libraries: `PIL`, `fitz`, `llm`, `ocr`, `pytesseract`, `requests`
* System dependencies: Ollama LLM, Tesseract OCR

**Usage:**
Run the script using `python main.py <path_to_pdf>`, replacing `<path_to_pdf>` with the PDF file path.


### üìÑ `llm/ollama_parser.py`
### Code File Summaries

#### llm/ollama_parser.py

**Purpose:** 
The `ollama_parser.py` file contains a function to parse invoice text and extract structured information using a local LLM (Large Language Model) API.

**Key Components:**
* The `generate_invoice_fields` function takes invoice text as input and returns a dictionary containing extracted invoice fields and raw LLM API output.
* The function relies on the `requests` library to send a POST request to the local LLM API.

**Behavior and Inputs/Outputs:**
* Input: Invoice text to be parsed
* Outputs:
  + Dictionary containing extracted invoice fields (e.g., invoice_id, invoice_number, invoice_date)
  + Raw output from the LLM API (parsed JSON response or error message)

**Important Dependencies and Considerations:**
* Local LLM API (e.g., Ollama) running on `http://localhost:11434/api/generate`
* `requests` and `json` libraries for HTTP requests and JSON parsing
* Potential implications for network usage and API usage limits due to the POST request to the local LLM API.


### üìÑ `ocr/ocr_handler.py`
### ocr_handler.py
#### Purpose
Extracts text from scanned PDFs using Optical Character Recognition (OCR).

#### Key Components
* `extract_text_from_pdf(pdf_path)`: Extracts text from each page of a scanned PDF.

#### Functionality
* **Input**: PDF file path (`pdf_path`)
* **Output**: Dictionary with page numbers as keys and extracted text as values
* **Side-Effects**:
  + Raises `FileNotFoundError` if the PDF file does not exist
  + Opens and closes the PDF document using `fitz`
* **Dependencies**:
  + `fitz` (PyMuPDF) for PDF processing
  + `pytesseract` for OCR functionality
  + `PIL` (Python Imaging Library) for image processing

#### Behavior and Intent
This code iterates through each page of a scanned PDF, applies OCR to extract text, and stores the results in a dictionary. It utilizes `fitz` for PDF processing, `pytesseract` for OCR, and `PIL` for image conversion, assuming necessary dependencies (including Tesseract OCR) are installed and configured properly. Note that this function only handles file not found errors and does not account for other potential exceptions during the OCR process.


### üìÑ `utils/text_cleaner.py`
### Code File Summaries: `utils/text_cleaner.py`

The `text_cleaner.py` module is designed to clean and normalize text extracted from Optical Character Recognition (OCR) processes. 

* **Purpose**: Improve readability and usability of OCR text for further processing.
* **Key Functions**:
  * `clean_ocr_text(text)`: Cleans and normalizes input OCR text.
* **Inputs/Outputs**:
  * Input: `text` (string) - Raw OCR text.
  * Output: `text` (string) - Cleaned and normalized OCR text.
* **Side-Effects**: None.
* **Important Dependencies**: Python's built-in `re` (regular expression) module.
* **Behavior and Intent**: 
  * Removes extra whitespaces and line breaks.
  * Fixes broken words with hyphenations at line ends.
  * Normalizes punctuation and special characters.
  * Replaces common OCR misreads and standardizes certain characters to improve text consistency.
  This module is intended for use as a preprocessing step for text extracted from OCR processes, making it suitable for downstream applications such as text analysis, indexing, or machine learning model input.

